<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>吴恩达深度学习笔记1-2--神经网络基础 | Hexo</title>
  <meta name="keywords" content=" 数据分析，深度学习 ">
  <meta name="description" content="吴恩达深度学习笔记1-2--神经网络基础 | Hexo">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="description" content="吴恩达课后编程作业1-2：具有神经网络思维的Logistic回归-本文学习自 何宽 的CSDN 博客 ，全文地址请点击：https://blog.csdn.net/u013733326/article/details/79639509?utm_source=copy本文所使用的资料已上传到百度网盘【点击下载】，请在开始之前下载好所需资料，然后将文件解压到你的代码文件同一级目录下,请确保你的代码那里">
<meta name="keywords" content="数据分析，深度学习">
<meta property="og:type" content="article">
<meta property="og:title" content="吴恩达课后编程作业1-2：具有神经网络思维的Logistic回归">
<meta property="og:url" content="http://yoursite.com/2018/09/23/吴恩达课后编程作业1-2：具有神经网络思维的Logistic回归/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="吴恩达课后编程作业1-2：具有神经网络思维的Logistic回归-本文学习自 何宽 的CSDN 博客 ，全文地址请点击：https://blog.csdn.net/u013733326/article/details/79639509?utm_source=copy本文所使用的资料已上传到百度网盘【点击下载】，请在开始之前下载好所需资料，然后将文件解压到你的代码文件同一级目录下,请确保你的代码那里">
<meta property="og:locale" content="default">
<meta property="og:image" content="http://yoursite.com/2018/09/23/吴恩达课后编程作业1-2：具有神经网络思维的Logistic回归/output_7_0.png">
<meta property="og:image" content="http://yoursite.com/2018/09/23/吴恩达课后编程作业1-2：具有神经网络思维的Logistic回归/output_42_0.png">
<meta property="og:image" content="http://yoursite.com/2018/09/23/吴恩达课后编程作业1-2：具有神经网络思维的Logistic回归/output_45_1.png">
<meta property="og:updated_time" content="2018-09-23T14:36:57.026Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="吴恩达课后编程作业1-2：具有神经网络思维的Logistic回归">
<meta name="twitter:description" content="吴恩达课后编程作业1-2：具有神经网络思维的Logistic回归-本文学习自 何宽 的CSDN 博客 ，全文地址请点击：https://blog.csdn.net/u013733326/article/details/79639509?utm_source=copy本文所使用的资料已上传到百度网盘【点击下载】，请在开始之前下载好所需资料，然后将文件解压到你的代码文件同一级目录下,请确保你的代码那里">
<meta name="twitter:image" content="http://yoursite.com/2018/09/23/吴恩达课后编程作业1-2：具有神经网络思维的Logistic回归/output_7_0.png">


<link rel="icon" href="/img/avatar.jpg">

<link rel="stylesheet" href="/css/style.css">

<link href="//cdn.bootcss.com/animate.css/3.5.2/animate.min.css" rel="stylesheet">
<link href="//cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet">

<link href="//cdn.bootcss.com/photoswipe/4.1.2/photoswipe.min.css" rel="stylesheet">
<link href="//cdn.bootcss.com/photoswipe/4.1.2/default-skin/default-skin.min.css" rel="stylesheet">

<script src="//cdn.bootcss.com/jquery/2.2.4/jquery.min.js"></script>
<script src="/js/jquery.autocomplete.min.js"></script>
<script src="//cdn.bootcss.com/highlight.js/9.12.0/highlight.min.js"></script>
<script>
    hljs.initHighlightingOnLoad();
</script>

<script src="//cdn.bootcss.com/nprogress/0.2.0/nprogress.min.js"></script>



<script src="//cdn.bootcss.com/jquery-cookie/1.4.1/jquery.cookie.min.js" ></script>

</head>
<div style="display: none">
  <input class="theme_disqus_on" value="false">
  <input class="theme_preload_comment" value="false">
</div>
<body>
<aside class="nav">
    <div class="nav-left">
        <a href="/" class="avatar_target">
    <img class="avatar" src="/img/avatar.jpg" />
</a>
<div class="author">
    <span>Wangjian</span>
</div>

<div class="icon">
    
    <a class="rss" title="rss" href="/atom.xml" target="_blank"></a>
    
    
    <a class="github" title="github" href="https://github.com/490317728" target="_blank"></a>
    
    
    
    
    
    
    
    
    <a class="email" title="email" href="mailto:490317728@qq.com"></a>
    
</div>



<ul>
    <li class="all active">全部文章</li>
    
    <li data-rel="hexo"> hexo </li>
    
    <li data-rel="小程序学习"> 小程序学习 </li>
    
    <li data-rel="数据分析"> 数据分析 </li>
    
</ul>
<div class="left-bottom">
    <div class="menus">
    
    
    
    
    </div>
    <div></div>
</div>
<input type="hidden" id="yelog_site_posts_number" value="33">
<input type="hidden" id="yelog_site_word_count" value="21.1k">
<div style="display: none">
    <span id="busuanzi_value_site_uv"></span>
    <span id="busuanzi_value_site_pv"></span>
</div>
    </div>
    <div class="nav-right">
        <div class="friends-area">
    <div class="friends-title">
        友情链接
        <i class="back-title-list"></i>
    </div>
    <div class="friends-content">
        <ul>
            
        </ul>
    </div>
</div>
        <div class="title-list">
    <form onkeydown="if(event.keyCode==13){return false;}">
        <input class="search" type="text" placeholder="Search..." autocomplete="off"id="local-search-input" >
        <i class="cross"></i>
        <span>
        <label for="tagswitch">Tags:</label>
        <input id="tagswitch" type="checkbox">
    </span>
    </form>
    <div class="tags-list">
    
    <li class="article-tag-list-item">
        <a href="javascript:" class="color5">hexo</a>
    </li>
    
    <li class="article-tag-list-item">
        <a href="javascript:" class="color2">github</a>
    </li>
    
    <li class="article-tag-list-item">
        <a href="javascript:" class="color4">小程序</a>
    </li>
    
    <li class="article-tag-list-item">
        <a href="javascript:" class="color5">数据分析</a>
    </li>
    
    <li class="article-tag-list-item">
        <a href="javascript:" class="color3">爬虫</a>
    </li>
    
    <li class="article-tag-list-item">
        <a href="javascript:" class="color5">数据分析，深度学习</a>
    </li>
    
    <div class="clearfix"></div>
</div>

    
    <nav id="title-list-nav">
        
        <a  class="hexo "
           href="/2018/07/05/hexo-github建立个人博客/"
           data-tag="hexo,github"
           data-author="" >
            <span class="post-title" title="hexo+github建立个人博客">hexo+github建立个人博客</span>
            <span class="post-date" title="2018-07-05 22:33:27">2018/07/05</span>
        </a>
        
        <a  class="hexo "
           href="/2018/08/07/hexo生成博文插入图片/"
           data-tag="hexo,github"
           data-author="" >
            <span class="post-title" title="hexo生成博文插入图片">hexo生成博文插入图片</span>
            <span class="post-date" title="2018-08-07 22:04:16">2018/08/07</span>
        </a>
        
        <a  class="hexo "
           href="/2018/08/05/hexo绑定自己的域名/"
           data-tag="hexo,github"
           data-author="" >
            <span class="post-title" title="hexo绑定自己的域名">hexo绑定自己的域名</span>
            <span class="post-date" title="2018-08-05 19:48:02">2018/08/05</span>
        </a>
        
        <a  class="小程序学习 "
           href="/2018/08/02/小程序tab选项卡-day10（2）/"
           data-tag="小程序"
           data-author="" >
            <span class="post-title" title="小程序reader+movie项目-day10（2）">小程序reader+movie项目-day10（2）</span>
            <span class="post-date" title="2018-08-02 22:00:05">2018/08/02</span>
        </a>
        
        <a  class="小程序学习 "
           href="/2018/08/05/阅读+电影小程序-day11/"
           data-tag="小程序"
           data-author="" >
            <span class="post-title" title="小程序reader+movie项目-day11">小程序reader+movie项目-day11</span>
            <span class="post-date" title="2018-08-05 21:59:05">2018/08/05</span>
        </a>
        
        <a  class="小程序学习 "
           href="/2018/08/07/阅读+电影小程序-day12/"
           data-tag="小程序"
           data-author="" >
            <span class="post-title" title="小程序reader+movie项目-day12">小程序reader+movie项目-day12</span>
            <span class="post-date" title="2018-08-07 21:46:05">2018/08/07</span>
        </a>
        
        <a  class="小程序学习 "
           href="/2018/08/08/阅读-电影小程序-day13/"
           data-tag="小程序"
           data-author="" >
            <span class="post-title" title="小程序reader+movie项目-day13">小程序reader+movie项目-day13</span>
            <span class="post-date" title="2018-08-08 21:48:05">2018/08/08</span>
        </a>
        
        <a  class="小程序学习 "
           href="/2018/07/09/阅读小程序-day1/"
           data-tag="小程序"
           data-author="" >
            <span class="post-title" title="小程序reader项目-day1">小程序reader项目-day1</span>
            <span class="post-date" title="2018-07-09 22:30:05">2018/07/09</span>
        </a>
        
        <a  class="小程序学习 "
           href="/2018/08/02/阅读小程序-day10/"
           data-tag="小程序"
           data-author="" >
            <span class="post-title" title="小程序reader项目-day10（1）">小程序reader项目-day10（1）</span>
            <span class="post-date" title="2018-08-02 21:30:05">2018/08/02</span>
        </a>
        
        <a  class="小程序学习 "
           href="/2018/07/11/阅读小程序-day2/"
           data-tag="小程序"
           data-author="" >
            <span class="post-title" title="小程序reader项目-day2">小程序reader项目-day2</span>
            <span class="post-date" title="2018-07-11 22:30:05">2018/07/11</span>
        </a>
        
        <a  class="小程序学习 "
           href="/2018/07/16/阅读小程序-day3/"
           data-tag="小程序"
           data-author="" >
            <span class="post-title" title="小程序reader项目-day3">小程序reader项目-day3</span>
            <span class="post-date" title="2018-07-16 22:30:05">2018/07/16</span>
        </a>
        
        <a  class="小程序学习 "
           href="/2018/07/17/阅读小程序-day4(1)/"
           data-tag="小程序"
           data-author="" >
            <span class="post-title" title="小程序reader项目-day4(1)">小程序reader项目-day4(1)</span>
            <span class="post-date" title="2018-07-17 22:00:05">2018/07/17</span>
        </a>
        
        <a  class="小程序学习 "
           href="/2018/07/17/阅读小程序-day4(2)/"
           data-tag="小程序"
           data-author="" >
            <span class="post-title" title="小程序reader项目-day4(2)">小程序reader项目-day4(2)</span>
            <span class="post-date" title="2018-07-17 22:15:05">2018/07/17</span>
        </a>
        
        <a  class="小程序学习 "
           href="/2018/07/18/阅读小程序-day5/"
           data-tag="小程序"
           data-author="" >
            <span class="post-title" title="小程序reader项目-day5">小程序reader项目-day5</span>
            <span class="post-date" title="2018-07-18 21:47:05">2018/07/18</span>
        </a>
        
        <a  class="小程序学习 "
           href="/2018/07/18/阅读小程序-day6/"
           data-tag="小程序"
           data-author="" >
            <span class="post-title" title="小程序reader项目-day6">小程序reader项目-day6</span>
            <span class="post-date" title="2018-07-18 22:06:05">2018/07/18</span>
        </a>
        
        <a  class="小程序学习 "
           href="/2018/07/30/阅读小程序-day7/"
           data-tag="小程序"
           data-author="" >
            <span class="post-title" title="小程序reader项目-day7">小程序reader项目-day7</span>
            <span class="post-date" title="2018-07-30 23:10:05">2018/07/30</span>
        </a>
        
        <a  class="小程序学习 "
           href="/2018/07/31/阅读小程序-day8/"
           data-tag="小程序"
           data-author="" >
            <span class="post-title" title="小程序reader项目-day8">小程序reader项目-day8</span>
            <span class="post-date" title="2018-07-31 22:50:05">2018/07/31</span>
        </a>
        
        <a  class="小程序学习 "
           href="/2018/08/01/阅读小程序-day9/"
           data-tag="小程序"
           data-author="" >
            <span class="post-title" title="小程序reader项目-day9">小程序reader项目-day9</span>
            <span class="post-date" title="2018-08-01 22:40:05">2018/08/01</span>
        </a>
        
        <a  class="小程序学习 "
           href="/2018/08/11/阅读+电影小程序-day14/"
           data-tag="小程序"
           data-author="" >
            <span class="post-title" title="小程序reader+movie项目-day14">小程序reader+movie项目-day14</span>
            <span class="post-date" title="2018-08-11 21:45:05">2018/08/11</span>
        </a>
        
        <a  class="小程序学习 "
           href="/2018/08/13/阅读+电影小程序-day15/"
           data-tag="小程序"
           data-author="" >
            <span class="post-title" title="小程序reader+movie项目-day15">小程序reader+movie项目-day15</span>
            <span class="post-date" title="2018-08-13 22:14:05">2018/08/13</span>
        </a>
        
        <a  class="小程序学习 "
           href="/2018/08/16/阅读+电影小程序-day16/"
           data-tag="小程序"
           data-author="" >
            <span class="post-title" title="小程序reader+movie项目-day16">小程序reader+movie项目-day16</span>
            <span class="post-date" title="2018-08-16 22:58:05">2018/08/16</span>
        </a>
        
        <a  class="小程序学习 "
           href="/2018/08/19/阅读+电影小程序-day17（2）/"
           data-tag="小程序"
           data-author="" >
            <span class="post-title" title="小程序reader+movie项目-day17（7）">小程序reader+movie项目-day17（7）</span>
            <span class="post-date" title="2018-08-19 16:09:05">2018/08/19</span>
        </a>
        
        <a  class="小程序学习 "
           href="/2018/08/19/阅读+电影小程序-day17（1）/"
           data-tag="小程序"
           data-author="" >
            <span class="post-title" title="小程序reader+movie项目-day17（1）">小程序reader+movie项目-day17（1）</span>
            <span class="post-date" title="2018-08-19 16:08:05">2018/08/19</span>
        </a>
        
        <a  class="数据分析 "
           href="/2018/08/19/python爬虫学习笔记1/"
           data-tag="数据分析,爬虫"
           data-author="" >
            <span class="post-title" title="python爬虫学习笔记1">python爬虫学习笔记1</span>
            <span class="post-date" title="2018-08-19 17:55:05">2018/08/19</span>
        </a>
        
        <a  class="数据分析 "
           href="/2018/08/20/python爬虫学习笔记2/"
           data-tag="数据分析,爬虫"
           data-author="" >
            <span class="post-title" title="python爬虫学习笔记2">python爬虫学习笔记2</span>
            <span class="post-date" title="2018-08-20 22:26:05">2018/08/20</span>
        </a>
        
        <a  class="小程序学习 "
           href="/2018/08/20/阅读+电影小程序-day18/"
           data-tag="小程序"
           data-author="" >
            <span class="post-title" title="小程序reader+movie项目-day18">小程序reader+movie项目-day18</span>
            <span class="post-date" title="2018-08-20 22:27:05">2018/08/20</span>
        </a>
        
        <a  class="小程序学习 "
           href="/2018/08/23/阅读+电影小程序-day19/"
           data-tag="小程序"
           data-author="" >
            <span class="post-title" title="小程序reader+movie项目-day19">小程序reader+movie项目-day19</span>
            <span class="post-date" title="2018-08-23 22:57:05">2018/08/23</span>
        </a>
        
        <a  class="小程序学习 "
           href="/2018/08/26/阅读+电影小程序-day20/"
           data-tag="小程序"
           data-author="" >
            <span class="post-title" title="小程序reader+movie项目-day20">小程序reader+movie项目-day20</span>
            <span class="post-date" title="2018-08-26 22:53:05">2018/08/26</span>
        </a>
        
        <a  class="数据分析 "
           href="/2018/08/29/杭州租房数据爬取（lianjia）/"
           data-tag="数据分析,爬虫"
           data-author="" >
            <span class="post-title" title="杭州租房数据--lianjia">杭州租房数据--lianjia</span>
            <span class="post-date" title="2018-08-29 22:51:05">2018/08/29</span>
        </a>
        
        <a  class="数据分析 "
           href="/2018/09/10/day1-numpy/"
           data-tag="数据分析"
           data-author="" >
            <span class="post-title" title="day1-numpy学习">day1-numpy学习</span>
            <span class="post-date" title="2018-09-10 23:07:05">2018/09/10</span>
        </a>
        
        <a  class="数据分析 "
           href="/2018/09/20/吴恩达Coursera深度学习课程笔记1-2--神经网络基础/"
           data-tag="数据分析，深度学习"
           data-author="" >
            <span class="post-title" title="吴恩达深度学习笔记1-2--神经网络基础">吴恩达深度学习笔记1-2--神经网络基础</span>
            <span class="post-date" title="2018-09-20 22:27:05">2018/09/20</span>
        </a>
        
        <a  class="数据分析 "
           href="/2018/09/23/吴恩达课后编程作业1-2：具有神经网络思维的Logistic回归/"
           data-tag="数据分析，深度学习"
           data-author="" >
            <span class="post-title" title="吴恩达课后编程作业1-2：具有神经网络思维的Logistic回归">吴恩达课后编程作业1-2：具有神经网络思维的Logistic回归</span>
            <span class="post-date" title="2018-09-23 22:37:05">2018/09/23</span>
        </a>
        
        <a  class="数据分析 "
           href="/2018/10/09/6000+个景点数据可视化/6000+个景点数据可视化/"
           data-tag="数据分析"
           data-author="" >
            <span class="post-title" title="6000+个景点数据可视化">6000+个景点数据可视化</span>
            <span class="post-date" title="2018-10-09 20:03:00">2018/10/09</span>
        </a>
        
    </nav>
</div>
    </div>
    <div class="hide-list">
        <div class="semicircle">
            <div class="brackets first"><</div>
            <div class="brackets">&gt;</div>
        </div>
    </div>
</aside>
<div class="post">
    <div class="pjax">
        <article id="post-吴恩达Coursera深度学习课程笔记1-2--神经网络基础" class="article article-type-post" itemscope itemprop="blogPost">
    
        <h1 class="article-title">吴恩达深度学习笔记1-2--神经网络基础</h1>
    
    <div class="article-meta">
        
        
        
        <span class="book">
            
            <a href="javascript:" data-rel="数据分析">数据分析</a>
            
        </span>
        
        
        <span class="tag">
            
            <a href="javascript:" class="color5">数据分析，深度学习</a>
            
        </span>
        
    </div>
    <div class="article-meta">
        
        创建时间:<time class="date" title='更新时间: 2018-09-20 22:27:52'>2018-09-20 22:27</time>
        
    </div>
    <div class="article-meta">
        
        <span>字数:1,699</span>
        
        
        <span id="busuanzi_container_page_pv">
            阅读:<span id="busuanzi_value_page_pv">
                <span class="count-comment">
                    <span class="spinner">
                      <div class="cube1"></div>
                      <div class="cube2"></div>
                    </span>
                </span>
            </span>
        </span>
        
        
    </div>
    
    <div class="toc-ref">
    
        <ol class="toc"><li class="toc-item toc-level-4"><a class="toc-link" href="#本篇笔记学习自CSDN的博主Koala-Tree"><span class="toc-text">本篇笔记学习自CSDN的博主Koala_Tree</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#看过吴恩达老师的课程后，不想自己做笔记了，就直接跟着博主又打了一遍，加深记忆"><span class="toc-text">看过吴恩达老师的课程后，不想自己做笔记了，就直接跟着博主又打了一遍，加深记忆</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#在此感谢Koala-Tree博主"><span class="toc-text">在此感谢Koala_Tree博主</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#以下为在Coursera上吴恩达老师的DeepLearning-ai课程项目中，第一部分《神经网络和深度学习》第二周课程部分关键点的笔记。"><span class="toc-text">以下为在Coursera上吴恩达老师的DeepLearning.ai课程项目中，第一部分《神经网络和深度学习》第二周课程部分关键点的笔记。</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#神经网络和深度学习—神经网络基础"><span class="toc-text">神经网络和深度学习—神经网络基础</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1、二分类问题"><span class="toc-text">1、二分类问题</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#·样本：-x-y-，训练样本包含m个；"><span class="toc-text">·样本：(x,y)，训练样本包含m个；</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#·其中x∈Rnx，表示样本x-包含nx个特征；"><span class="toc-text">·其中x∈Rnx，表示样本x 包含nx个特征；</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#·y∈0-1，目标值属于0、1分类；"><span class="toc-text">·y∈0,1，目标值属于0、1分类；</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#·训练数据：-x-1-y-1-x-2-y-2-⋯-x-m-y-m"><span class="toc-text">·训练数据：{(x(1),y(1)),(x(2),y(2)),⋯,(x(m),y(m))}</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#输入神经网络时样本数据的形状："><span class="toc-text">输入神经网络时样本数据的形状：</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#X-shape-nx-m"><span class="toc-text">X.shape=(nx,m)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#目标数据的形状："><span class="toc-text">目标数据的形状：</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Y-y-1-y-2-⋯-y-m"><span class="toc-text">Y=[y(1),y(2),⋯,y(m)]</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Y-shape-1-m"><span class="toc-text">Y.shape=(1,m)</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-logistic-Regression"><span class="toc-text">2. logistic Regression</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#逻辑回归中，预测值："><span class="toc-text">逻辑回归中，预测值：</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#其表示为1的概率，取值范围在-0-1-之间。"><span class="toc-text">其表示为1的概率，取值范围在[0,1]之间。</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#引入Sigmoid函数，预测值："><span class="toc-text">引入Sigmoid函数，预测值：</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#其中"><span class="toc-text">其中</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#注意点：函数的一阶导数可以用其自身表示，（对z求导可以得到）"><span class="toc-text">注意点：函数的一阶导数可以用其自身表示，（对z求导可以得到）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#这里可以解释梯度消失的问题，当z-0时，导数最大，但是导数最大为σ′-0-σ-0-1−σ-0-0-5-1−0-5-0-25，这里导数仅为原函数值的0-25倍。"><span class="toc-text">这里可以解释梯度消失的问题，当z=0时，导数最大，但是导数最大为σ′(0)=σ(0)(1−σ(0))=0.5(1−0.5)=0.25，这里导数仅为原函数值的0.25倍。</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#参数梯度下降公式的不断更新，σ′-z"><span class="toc-text">参数梯度下降公式的不断更新，σ′(z)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#会变得越来越小，每次迭代参数更新的步伐越来越小，最终接近于0，产生梯度消失的现象。"><span class="toc-text">会变得越来越小，每次迭代参数更新的步伐越来越小，最终接近于0，产生梯度消失的现象。</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-logistic回归-损失函数"><span class="toc-text">3. logistic回归 损失函数</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#一般经验来说，使用平方错误（squared-error）来衡量Loss-Function："><span class="toc-text">一般经验来说，使用平方错误（squared error）来衡量Loss Function：</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#但是，对于logistic-regression-来说，一般不适用平方错误来作为Loss-Function，这是因为上面的平方错误损失函数一般是非凸函数（non-convex），其在使用低度下降算法的时候，容易得到局部最优解，而不是全局最优解。因此要选择凸函数。"><span class="toc-text">但是，对于logistic regression 来说，一般不适用平方错误来作为Loss Function，这是因为上面的平方错误损失函数一般是非凸函数（non-convex），其在使用低度下降算法的时候，容易得到局部最优解，而不是全局最优解。因此要选择凸函数。</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#逻辑回归的Loss-Function："><span class="toc-text">逻辑回归的Loss Function：</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#当y-1时，L-y’-y-−logy’。如果y’越接近1，L-y’-y-≈0，表示预测效果越好；如果y’越接近0，L-y’-y-≈-∞，表示预测效果越差；当y-0时，L-y’-y-−log-1−y’-。如果y’越接近0，L-y’-y-≈0，表示预测效果越好；如果y-越接1，L-y’-y-≈-∞，表示预测效果越差；我们的目标是最小化样本点的损失Loss-Function，损失函数是针对单个样本点的。"><span class="toc-text">当y=1时，L(y’,y)=−logy’。如果y’越接近1，L(y’,y)≈0，表示预测效果越好；如果y’越接近0，L(y’,y)≈+∞，表示预测效果越差；当y=0时，L(y’,y)=−log(1−y’)。如果y’越接近0，L(y’,y)≈0，表示预测效果越好；如果y^越接1，L(y’,y)≈+∞，表示预测效果越差；我们的目标是最小化样本点的损失Loss Function，损失函数是针对单个样本点的。</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Cost-function"><span class="toc-text">Cost function</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#全部训练数据集的Loss-function总和的平均值即为训练集的代价函数（Cost-function）。"><span class="toc-text">全部训练数据集的Loss function总和的平均值即为训练集的代价函数（Cost function）。</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Cost-function是待求系数w和b的函数；我们的目标就是迭代计算出最佳的w和b的值，最小化Cost-function，让其尽可能地接近于0。"><span class="toc-text">Cost function是待求系数w和b的函数；我们的目标就是迭代计算出最佳的w和b的值，最小化Cost function，让其尽可能地接近于0。</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-梯度下降"><span class="toc-text">4. 梯度下降</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#用梯度下降法（Gradient-Descent）算法来最小化Cost-function，以计算出合适的w和b的值。"><span class="toc-text">用梯度下降法（Gradient Descent）算法来最小化Cost function，以计算出合适的w和b的值。</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#每次迭代更新的修正表达式："><span class="toc-text">每次迭代更新的修正表达式：</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#在程序代码中，我们通常使用dw来表示∂J-w-b-∂w，用db来表示∂J-w-b-∂b。"><span class="toc-text">在程序代码中，我们通常使用dw来表示∂J(w,b)/∂w，用db来表示∂J(w,b)/∂b。</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-逻辑回归中的梯度下降法"><span class="toc-text">5. 逻辑回归中的梯度下降法</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#对单个样本而言，逻辑回归Loss-function表达式："><span class="toc-text">对单个样本而言，逻辑回归Loss function表达式：</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#反向传播过程："><span class="toc-text">反向传播过程：</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#前面过程的da、dz求导："><span class="toc-text">前面过程的da、dz求导：</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#再对w1、w2和b进行求导："><span class="toc-text">再对w1、w2和b进行求导：</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#梯度下降法："><span class="toc-text">梯度下降法：</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#6-m个样本的梯度下降"><span class="toc-text">6. m个样本的梯度下降</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#对m个样本来说，其Cost-function表达式如下："><span class="toc-text">对m个样本来说，其Cost function表达式如下：</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Cost-function-关于w和b的偏导数可以写成所有样本点偏导数和的平均形式"><span class="toc-text">Cost function 关于w和b的偏导数可以写成所有样本点偏导数和的平均形式</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#7-向量化（Vectorization）"><span class="toc-text">7. 向量化（Vectorization）</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#在深度学习的算法中，我们通常拥有大量的数据，在程序的编写过程中，应该尽最大可能的少使用loop循环语句，利用python可以实现矩阵运算，进而来提高程序的运行速度，避免for循环的使用。"><span class="toc-text">在深度学习的算法中，我们通常拥有大量的数据，在程序的编写过程中，应该尽最大可能的少使用loop循环语句，利用python可以实现矩阵运算，进而来提高程序的运行速度，避免for循环的使用。</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#逻辑回归向量化"><span class="toc-text">逻辑回归向量化</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#·输入矩阵X：（nx-m）"><span class="toc-text">·输入矩阵X：（nx,m）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#·权重矩阵w：（nx-1）"><span class="toc-text">·权重矩阵w：（nx,1）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#·偏置b：为一个常数"><span class="toc-text">·偏置b：为一个常数</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#·输出矩阵Y：（1-m）"><span class="toc-text">·输出矩阵Y：（1,m）</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#所有m个样本的线性输出Z可以用矩阵表示："><span class="toc-text">所有m个样本的线性输出Z可以用矩阵表示：</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#python代码："><span class="toc-text">python代码：</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#逻辑回归梯度下降输出向量化"><span class="toc-text">逻辑回归梯度下降输出向量化</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#·dZ对于m个样本，维度为（1-m），表示为："><span class="toc-text">·dZ对于m个样本，维度为（1,m），表示为：</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#·db可以表示为："><span class="toc-text">·db可以表示为：</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#python代码：-1"><span class="toc-text">python代码：</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#·dw可表示为："><span class="toc-text">·dw可表示为：</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#python代码：-2"><span class="toc-text">python代码：</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#单次迭代梯度下降算法流程"><span class="toc-text">单次迭代梯度下降算法流程</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Z-np-dot-w-T-X-b"><span class="toc-text">Z = np.dot(w.T,X) + b</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#A-sigmoid-Z"><span class="toc-text">A = sigmoid(Z)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#dZ-A-Y"><span class="toc-text">dZ = A-Y</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#dw-1-m-np-dot-X-dZ-T"><span class="toc-text">dw = 1/m*np.dot(X,dZ.T)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#db-1-m-np-sum-dZ"><span class="toc-text">db = 1/m*np.sum(dZ)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#w-w-alpha-dw"><span class="toc-text">w = w - alpha*dw</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#b-b-alpha-db"><span class="toc-text">b = b - alpha*db</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#8-python的notation"><span class="toc-text">8. python的notation</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#虽然在Python有广播的机制，但是在Python程序中，为了保证矩阵运算的正确性，可以使用reshape-函数来对矩阵设定所需要进行计算的维度，这是个好的习惯；"><span class="toc-text">虽然在Python有广播的机制，但是在Python程序中，为了保证矩阵运算的正确性，可以使用reshape()函数来对矩阵设定所需要进行计算的维度，这是个好的习惯；</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#如果用下列语句来定义一个向量，则这条语句生成的a的维度为（5，），既不是行向量也不是列向量，称为秩（rank）为1的array，如果对a进行转置，则会得到a本身，这在计算中会给我们带来一些问题。"><span class="toc-text">如果用下列语句来定义一个向量，则这条语句生成的a的维度为（5，），既不是行向量也不是列向量，称为秩（rank）为1的array，如果对a进行转置，则会得到a本身，这在计算中会给我们带来一些问题。</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#如果需要定义（5，1）或者（1，5）向量，要使用下面标准的语句："><span class="toc-text">如果需要定义（5，1）或者（1，5）向量，要使用下面标准的语句：</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#可以使用assert语句对向量或数组的维度进行判断。assert会对内嵌语句进行判断，即判断a的维度是不是（5，1），如果不是，则程序在此处停止。使用assert语句也是一种很好的习惯，能够帮助我们及时检查、发现语句是否正确。"><span class="toc-text">可以使用assert语句对向量或数组的维度进行判断。assert会对内嵌语句进行判断，即判断a的维度是不是（5，1），如果不是，则程序在此处停止。使用assert语句也是一种很好的习惯，能够帮助我们及时检查、发现语句是否正确。</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#可以使用reshape函数对数组设定所需的维度"><span class="toc-text">可以使用reshape函数对数组设定所需的维度</span></a>
    
<style>
    .left-col .switch-btn,
    .left-col .switch-area {
        display: none;
    }
    .toc-level-3 i,
    .toc-level-3 ol {
        display: none !important;
    }
</style>
</div>
    <div class="article-entry" itemprop="articleBody">
      
        <h4 id="本篇笔记学习自CSDN的博主Koala-Tree"><a href="#本篇笔记学习自CSDN的博主Koala-Tree" class="headerlink" title="本篇笔记学习自CSDN的博主Koala_Tree"></a>本篇笔记学习自CSDN的博主Koala_Tree</h4><h4 id="看过吴恩达老师的课程后，不想自己做笔记了，就直接跟着博主又打了一遍，加深记忆"><a href="#看过吴恩达老师的课程后，不想自己做笔记了，就直接跟着博主又打了一遍，加深记忆" class="headerlink" title="看过吴恩达老师的课程后，不想自己做笔记了，就直接跟着博主又打了一遍，加深记忆"></a>看过吴恩达老师的课程后，不想自己做笔记了，就直接跟着博主又打了一遍，加深记忆</h4><h4 id="在此感谢Koala-Tree博主"><a href="#在此感谢Koala-Tree博主" class="headerlink" title="在此感谢Koala_Tree博主"></a>在此感谢Koala_Tree博主</h4><h4 id="以下为在Coursera上吴恩达老师的DeepLearning-ai课程项目中，第一部分《神经网络和深度学习》第二周课程部分关键点的笔记。"><a href="#以下为在Coursera上吴恩达老师的DeepLearning-ai课程项目中，第一部分《神经网络和深度学习》第二周课程部分关键点的笔记。" class="headerlink" title="以下为在Coursera上吴恩达老师的DeepLearning.ai课程项目中，第一部分《神经网络和深度学习》第二周课程部分关键点的笔记。"></a>以下为在Coursera上吴恩达老师的DeepLearning.ai课程项目中，第一部分《神经网络和深度学习》第二周课程部分关键点的笔记。</h4><h2 id="神经网络和深度学习—神经网络基础"><a href="#神经网络和深度学习—神经网络基础" class="headerlink" title="神经网络和深度学习—神经网络基础"></a>神经网络和深度学习—神经网络基础</h2><h2 id="1、二分类问题"><a href="#1、二分类问题" class="headerlink" title="1、二分类问题"></a>1、二分类问题</h2><h3 id="·样本：-x-y-，训练样本包含m个；"><a href="#·样本：-x-y-，训练样本包含m个；" class="headerlink" title="·样本：(x,y)，训练样本包含m个；"></a>·样本：(x,y)，训练样本包含m个；</h3><h3 id="·其中x∈Rnx，表示样本x-包含nx个特征；"><a href="#·其中x∈Rnx，表示样本x-包含nx个特征；" class="headerlink" title="·其中x∈Rnx，表示样本x 包含nx个特征；"></a>·其中x∈Rnx，表示样本x 包含nx个特征；</h3><h3 id="·y∈0-1，目标值属于0、1分类；"><a href="#·y∈0-1，目标值属于0、1分类；" class="headerlink" title="·y∈0,1，目标值属于0、1分类；"></a>·y∈0,1，目标值属于0、1分类；</h3><h3 id="·训练数据：-x-1-y-1-x-2-y-2-⋯-x-m-y-m"><a href="#·训练数据：-x-1-y-1-x-2-y-2-⋯-x-m-y-m" class="headerlink" title="·训练数据：{(x(1),y(1)),(x(2),y(2)),⋯,(x(m),y(m))}"></a>·训练数据：{(x(1),y(1)),(x(2),y(2)),⋯,(x(m),y(m))}</h3><h4 id="输入神经网络时样本数据的形状："><a href="#输入神经网络时样本数据的形状：" class="headerlink" title="输入神经网络时样本数据的形状："></a>输入神经网络时样本数据的形状：</h4><p><img src="/2018/09/20/吴恩达Coursera深度学习课程笔记1-2--神经网络基础/attachment:new.png" alt="new.png"></p>
<h3 id="X-shape-nx-m"><a href="#X-shape-nx-m" class="headerlink" title="X.shape=(nx,m)"></a>X.shape=(nx,m)</h3><h3 id="目标数据的形状："><a href="#目标数据的形状：" class="headerlink" title="目标数据的形状："></a>目标数据的形状：</h3><h3 id="Y-y-1-y-2-⋯-y-m"><a href="#Y-y-1-y-2-⋯-y-m" class="headerlink" title="Y=[y(1),y(2),⋯,y(m)]"></a>Y=[y(1),y(2),⋯,y(m)]</h3><h3 id="Y-shape-1-m"><a href="#Y-shape-1-m" class="headerlink" title="Y.shape=(1,m)"></a>Y.shape=(1,m)</h3><h2 id="2-logistic-Regression"><a href="#2-logistic-Regression" class="headerlink" title="2. logistic Regression"></a>2. logistic Regression</h2><h3 id="逻辑回归中，预测值："><a href="#逻辑回归中，预测值：" class="headerlink" title="逻辑回归中，预测值："></a>逻辑回归中，预测值：</h3><p>$$ h^=P(y=1|x) $$</p>
<h3 id="其表示为1的概率，取值范围在-0-1-之间。"><a href="#其表示为1的概率，取值范围在-0-1-之间。" class="headerlink" title="其表示为1的概率，取值范围在[0,1]之间。"></a>其表示为1的概率，取值范围在[0,1]之间。</h3><h3 id="引入Sigmoid函数，预测值："><a href="#引入Sigmoid函数，预测值：" class="headerlink" title="引入Sigmoid函数，预测值："></a>引入Sigmoid函数，预测值：</h3><p>$$ y^=Sigmoid(w^Tx+b)=σ(w^Tx+b) $$</p>
<h3 id="其中"><a href="#其中" class="headerlink" title="其中"></a>其中</h3><p>$$ Sigmoid(z)=σ(z)=1/（1+e^{-z}）$$</p>
<h3 id="注意点：函数的一阶导数可以用其自身表示，（对z求导可以得到）"><a href="#注意点：函数的一阶导数可以用其自身表示，（对z求导可以得到）" class="headerlink" title="注意点：函数的一阶导数可以用其自身表示，（对z求导可以得到）"></a>注意点：函数的一阶导数可以用其自身表示，（对z求导可以得到）</h3><p>$$ σ′(z)=σ(z)(1−σ(z)) $$</p>
<h3 id="这里可以解释梯度消失的问题，当z-0时，导数最大，但是导数最大为σ′-0-σ-0-1−σ-0-0-5-1−0-5-0-25，这里导数仅为原函数值的0-25倍。"><a href="#这里可以解释梯度消失的问题，当z-0时，导数最大，但是导数最大为σ′-0-σ-0-1−σ-0-0-5-1−0-5-0-25，这里导数仅为原函数值的0-25倍。" class="headerlink" title="这里可以解释梯度消失的问题，当z=0时，导数最大，但是导数最大为σ′(0)=σ(0)(1−σ(0))=0.5(1−0.5)=0.25，这里导数仅为原函数值的0.25倍。"></a>这里可以解释梯度消失的问题，当z=0时，导数最大，但是导数最大为σ′(0)=σ(0)(1−σ(0))=0.5(1−0.5)=0.25，这里导数仅为原函数值的0.25倍。</h3><h3 id="参数梯度下降公式的不断更新，σ′-z"><a href="#参数梯度下降公式的不断更新，σ′-z" class="headerlink" title="参数梯度下降公式的不断更新，σ′(z)"></a>参数梯度下降公式的不断更新，σ′(z)</h3><h3 id="会变得越来越小，每次迭代参数更新的步伐越来越小，最终接近于0，产生梯度消失的现象。"><a href="#会变得越来越小，每次迭代参数更新的步伐越来越小，最终接近于0，产生梯度消失的现象。" class="headerlink" title="会变得越来越小，每次迭代参数更新的步伐越来越小，最终接近于0，产生梯度消失的现象。"></a>会变得越来越小，每次迭代参数更新的步伐越来越小，最终接近于0，产生梯度消失的现象。</h3><h2 id="3-logistic回归-损失函数"><a href="#3-logistic回归-损失函数" class="headerlink" title="3. logistic回归 损失函数"></a>3. logistic回归 损失函数</h2><h4 id="一般经验来说，使用平方错误（squared-error）来衡量Loss-Function："><a href="#一般经验来说，使用平方错误（squared-error）来衡量Loss-Function：" class="headerlink" title="一般经验来说，使用平方错误（squared error）来衡量Loss Function："></a>一般经验来说，使用平方错误（squared error）来衡量Loss Function：</h4><p>$$ L(y^,y)=1/2(y^−y)^2 $$</p>
<h4 id="但是，对于logistic-regression-来说，一般不适用平方错误来作为Loss-Function，这是因为上面的平方错误损失函数一般是非凸函数（non-convex），其在使用低度下降算法的时候，容易得到局部最优解，而不是全局最优解。因此要选择凸函数。"><a href="#但是，对于logistic-regression-来说，一般不适用平方错误来作为Loss-Function，这是因为上面的平方错误损失函数一般是非凸函数（non-convex），其在使用低度下降算法的时候，容易得到局部最优解，而不是全局最优解。因此要选择凸函数。" class="headerlink" title="但是，对于logistic regression 来说，一般不适用平方错误来作为Loss Function，这是因为上面的平方错误损失函数一般是非凸函数（non-convex），其在使用低度下降算法的时候，容易得到局部最优解，而不是全局最优解。因此要选择凸函数。"></a>但是，对于logistic regression 来说，一般不适用平方错误来作为Loss Function，这是因为上面的平方错误损失函数一般是非凸函数（non-convex），其在使用低度下降算法的时候，容易得到局部最优解，而不是全局最优解。因此要选择凸函数。</h4><h3 id="逻辑回归的Loss-Function："><a href="#逻辑回归的Loss-Function：" class="headerlink" title="逻辑回归的Loss Function："></a>逻辑回归的Loss Function：</h3><p> $$ L(y’,y)=−(ylogy’+(1−y)log(1−y’)) $$</p>
<h3 id="当y-1时，L-y’-y-−logy’。如果y’越接近1，L-y’-y-≈0，表示预测效果越好；如果y’越接近0，L-y’-y-≈-∞，表示预测效果越差；当y-0时，L-y’-y-−log-1−y’-。如果y’越接近0，L-y’-y-≈0，表示预测效果越好；如果y-越接1，L-y’-y-≈-∞，表示预测效果越差；我们的目标是最小化样本点的损失Loss-Function，损失函数是针对单个样本点的。"><a href="#当y-1时，L-y’-y-−logy’。如果y’越接近1，L-y’-y-≈0，表示预测效果越好；如果y’越接近0，L-y’-y-≈-∞，表示预测效果越差；当y-0时，L-y’-y-−log-1−y’-。如果y’越接近0，L-y’-y-≈0，表示预测效果越好；如果y-越接1，L-y’-y-≈-∞，表示预测效果越差；我们的目标是最小化样本点的损失Loss-Function，损失函数是针对单个样本点的。" class="headerlink" title="当y=1时，L(y’,y)=−logy’。如果y’越接近1，L(y’,y)≈0，表示预测效果越好；如果y’越接近0，L(y’,y)≈+∞，表示预测效果越差；当y=0时，L(y’,y)=−log(1−y’)。如果y’越接近0，L(y’,y)≈0，表示预测效果越好；如果y^越接1，L(y’,y)≈+∞，表示预测效果越差；我们的目标是最小化样本点的损失Loss Function，损失函数是针对单个样本点的。"></a>当y=1时，L(y’,y)=−logy’。如果y’越接近1，L(y’,y)≈0，表示预测效果越好；如果y’越接近0，L(y’,y)≈+∞，表示预测效果越差；当y=0时，L(y’,y)=−log(1−y’)。如果y’越接近0，L(y’,y)≈0，表示预测效果越好；如果y^越接1，L(y’,y)≈+∞，表示预测效果越差；我们的目标是最小化样本点的损失Loss Function，损失函数是针对单个样本点的。</h3><h3 id="Cost-function"><a href="#Cost-function" class="headerlink" title="Cost function"></a>Cost function</h3><h3 id="全部训练数据集的Loss-function总和的平均值即为训练集的代价函数（Cost-function）。"><a href="#全部训练数据集的Loss-function总和的平均值即为训练集的代价函数（Cost-function）。" class="headerlink" title="全部训练数据集的Loss function总和的平均值即为训练集的代价函数（Cost function）。"></a>全部训练数据集的Loss function总和的平均值即为训练集的代价函数（Cost function）。</h3><p>$$ J(w,b)=1/m∑i=1/mL(y’^{(i)},y^{(i)})=−1/m\sum_{i=1}^m[y^{(i)}logy’^{(i)}+(1−y^{(i)})log(1−y’^{(i)})] $$</p>
<h3 id="Cost-function是待求系数w和b的函数；我们的目标就是迭代计算出最佳的w和b的值，最小化Cost-function，让其尽可能地接近于0。"><a href="#Cost-function是待求系数w和b的函数；我们的目标就是迭代计算出最佳的w和b的值，最小化Cost-function，让其尽可能地接近于0。" class="headerlink" title="Cost function是待求系数w和b的函数；我们的目标就是迭代计算出最佳的w和b的值，最小化Cost function，让其尽可能地接近于0。"></a>Cost function是待求系数w和b的函数；我们的目标就是迭代计算出最佳的w和b的值，最小化Cost function，让其尽可能地接近于0。</h3><h2 id="4-梯度下降"><a href="#4-梯度下降" class="headerlink" title="4. 梯度下降"></a>4. 梯度下降</h2><h3 id="用梯度下降法（Gradient-Descent）算法来最小化Cost-function，以计算出合适的w和b的值。"><a href="#用梯度下降法（Gradient-Descent）算法来最小化Cost-function，以计算出合适的w和b的值。" class="headerlink" title="用梯度下降法（Gradient Descent）算法来最小化Cost function，以计算出合适的w和b的值。"></a>用梯度下降法（Gradient Descent）算法来最小化Cost function，以计算出合适的w和b的值。</h3><h3 id="每次迭代更新的修正表达式："><a href="#每次迭代更新的修正表达式：" class="headerlink" title="每次迭代更新的修正表达式："></a>每次迭代更新的修正表达式：</h3><p>$$ w:=w−α\frac{∂J(w,b)}{∂w} $$</p>
<p>$$ b:=b−α\frac{∂J(w,b)}{∂b} $$</p>
<h3 id="在程序代码中，我们通常使用dw来表示∂J-w-b-∂w，用db来表示∂J-w-b-∂b。"><a href="#在程序代码中，我们通常使用dw来表示∂J-w-b-∂w，用db来表示∂J-w-b-∂b。" class="headerlink" title="在程序代码中，我们通常使用dw来表示∂J(w,b)/∂w，用db来表示∂J(w,b)/∂b。"></a>在程序代码中，我们通常使用dw来表示∂J(w,b)/∂w，用db来表示∂J(w,b)/∂b。</h3><h2 id="5-逻辑回归中的梯度下降法"><a href="#5-逻辑回归中的梯度下降法" class="headerlink" title="5. 逻辑回归中的梯度下降法"></a>5. 逻辑回归中的梯度下降法</h2><h3 id="对单个样本而言，逻辑回归Loss-function表达式："><a href="#对单个样本而言，逻辑回归Loss-function表达式：" class="headerlink" title="对单个样本而言，逻辑回归Loss function表达式："></a>对单个样本而言，逻辑回归Loss function表达式：</h3><p>$$ z=w^Tx+b $$<br>$$ y’=a=σ(z) $$<br>$$ L(a,y)=−(ylog(a)+(1−y)log(1−a)) $$</p>
<h3 id="反向传播过程："><a href="#反向传播过程：" class="headerlink" title="反向传播过程："></a>反向传播过程：</h3><p><img src="/2018/09/20/吴恩达Coursera深度学习课程笔记1-2--神经网络基础/attachment:2.1.2.png" alt="2.1.2.png"></p>
<h3 id="前面过程的da、dz求导："><a href="#前面过程的da、dz求导：" class="headerlink" title="前面过程的da、dz求导："></a>前面过程的da、dz求导：</h3><p>$$ da=\frac{∂L}{∂a}=−\frac{y}{a}+\frac{1−y}{1−a} $$<br>$$ dz=\frac{∂L}{∂z}=\frac{∂L}{∂a}*\frac{∂a}{∂z}=(−\frac{y}{a}+\frac{1−y}{1−a})⋅a(1−a)=a−y $$</p>
<h3 id="再对w1、w2和b进行求导："><a href="#再对w1、w2和b进行求导：" class="headerlink" title="再对w1、w2和b进行求导："></a>再对w1、w2和b进行求导：</h3><p>$$ dw1=\frac{∂L}{∂w1}=\frac{∂L}{∂z}⋅\frac{∂z}{∂w1}=x1⋅dz=x1(a−y) $$<br>$$ db=\frac{∂L}{∂b}=\frac{∂L}{∂z}⋅\frac{∂z}{∂b}=1⋅dz=a−y $$</p>
<h3 id="梯度下降法："><a href="#梯度下降法：" class="headerlink" title="梯度下降法："></a>梯度下降法：</h3><p>$$ w1:=w1−αdw1$$<br>$$ w2:=w2−αdw2$$<br>$$b:=b−αdb$$</p>
<h2 id="6-m个样本的梯度下降"><a href="#6-m个样本的梯度下降" class="headerlink" title="6. m个样本的梯度下降"></a>6. m个样本的梯度下降</h2><h3 id="对m个样本来说，其Cost-function表达式如下："><a href="#对m个样本来说，其Cost-function表达式如下：" class="headerlink" title="对m个样本来说，其Cost function表达式如下："></a>对m个样本来说，其Cost function表达式如下：</h3><p>$$ z^{(i)}=w^Tx^{(i)}+b $$<br>$$ y’^(i)=a^{(i)}=σ(z^{(i)}) $$<br>$$ J(w,b)=\frac{1}{m}\sum_{i=1}^mL(y’^{(i)},y^{(i)})=\frac{1}{m}\sum_{i=1}^m[y^{(i)}logy’^{(i)}+(1−y^{(i)})log(1−y’^{(i)})] $$</p>
<h3 id="Cost-function-关于w和b的偏导数可以写成所有样本点偏导数和的平均形式"><a href="#Cost-function-关于w和b的偏导数可以写成所有样本点偏导数和的平均形式" class="headerlink" title="Cost function 关于w和b的偏导数可以写成所有样本点偏导数和的平均形式"></a>Cost function 关于w和b的偏导数可以写成所有样本点偏导数和的平均形式</h3><p>$$ dw1=\frac{1}{m}\sum_{i=1}^mx1^{(i)}(a^{(i)}−y^{(i)}) $$<br>$$ db=\frac{1}{m}\sum_{i=1}^m(a^{(i)}−y^{(i)}) $$</p>
<h2 id="7-向量化（Vectorization）"><a href="#7-向量化（Vectorization）" class="headerlink" title="7. 向量化（Vectorization）"></a>7. 向量化（Vectorization）</h2><h3 id="在深度学习的算法中，我们通常拥有大量的数据，在程序的编写过程中，应该尽最大可能的少使用loop循环语句，利用python可以实现矩阵运算，进而来提高程序的运行速度，避免for循环的使用。"><a href="#在深度学习的算法中，我们通常拥有大量的数据，在程序的编写过程中，应该尽最大可能的少使用loop循环语句，利用python可以实现矩阵运算，进而来提高程序的运行速度，避免for循环的使用。" class="headerlink" title="在深度学习的算法中，我们通常拥有大量的数据，在程序的编写过程中，应该尽最大可能的少使用loop循环语句，利用python可以实现矩阵运算，进而来提高程序的运行速度，避免for循环的使用。"></a>在深度学习的算法中，我们通常拥有大量的数据，在程序的编写过程中，应该尽最大可能的少使用loop循环语句，利用python可以实现矩阵运算，进而来提高程序的运行速度，避免for循环的使用。</h3><h3 id="逻辑回归向量化"><a href="#逻辑回归向量化" class="headerlink" title="逻辑回归向量化"></a>逻辑回归向量化</h3><h4 id="·输入矩阵X：（nx-m）"><a href="#·输入矩阵X：（nx-m）" class="headerlink" title="·输入矩阵X：（nx,m）"></a>·输入矩阵X：（nx,m）</h4><h4 id="·权重矩阵w：（nx-1）"><a href="#·权重矩阵w：（nx-1）" class="headerlink" title="·权重矩阵w：（nx,1）"></a>·权重矩阵w：（nx,1）</h4><h4 id="·偏置b：为一个常数"><a href="#·偏置b：为一个常数" class="headerlink" title="·偏置b：为一个常数"></a>·偏置b：为一个常数</h4><h4 id="·输出矩阵Y：（1-m）"><a href="#·输出矩阵Y：（1-m）" class="headerlink" title="·输出矩阵Y：（1,m）"></a>·输出矩阵Y：（1,m）</h4><h3 id="所有m个样本的线性输出Z可以用矩阵表示："><a href="#所有m个样本的线性输出Z可以用矩阵表示：" class="headerlink" title="所有m个样本的线性输出Z可以用矩阵表示："></a>所有m个样本的线性输出Z可以用矩阵表示：</h3><p>$$ Z=w^TX+b $$</p>
<h3 id="python代码："><a href="#python代码：" class="headerlink" title="python代码："></a>python代码：</h3><pre><code class="python">Z = np.dot(w.T,X) + b
A = sigmoid(Z)
</code></pre>
<h3 id="逻辑回归梯度下降输出向量化"><a href="#逻辑回归梯度下降输出向量化" class="headerlink" title="逻辑回归梯度下降输出向量化"></a>逻辑回归梯度下降输出向量化</h3><h4 id="·dZ对于m个样本，维度为（1-m），表示为："><a href="#·dZ对于m个样本，维度为（1-m），表示为：" class="headerlink" title="·dZ对于m个样本，维度为（1,m），表示为："></a>·dZ对于m个样本，维度为（1,m），表示为：</h4><p>$$ dZ=A−Y $$</p>
<h4 id="·db可以表示为："><a href="#·db可以表示为：" class="headerlink" title="·db可以表示为："></a>·db可以表示为：</h4><p>$$ db=\frac{1}{m}\sum_{i=1}^mdz^{(i)} $$</p>
<h3 id="python代码：-1"><a href="#python代码：-1" class="headerlink" title="python代码："></a>python代码：</h3><pre><code class="python">db = 1/m*np.sum(dZ)
</code></pre>
<h4 id="·dw可表示为："><a href="#·dw可表示为：" class="headerlink" title="·dw可表示为："></a>·dw可表示为：</h4><p>$$ dw=\frac{1}{m}X⋅dZ^T $$</p>
<h3 id="python代码：-2"><a href="#python代码：-2" class="headerlink" title="python代码："></a>python代码：</h3><pre><code class="python">dw = 1/m*np.dot(X,dZ.T)
</code></pre>
<h3 id="单次迭代梯度下降算法流程"><a href="#单次迭代梯度下降算法流程" class="headerlink" title="单次迭代梯度下降算法流程"></a>单次迭代梯度下降算法流程</h3><h4 id="Z-np-dot-w-T-X-b"><a href="#Z-np-dot-w-T-X-b" class="headerlink" title="Z = np.dot(w.T,X) + b"></a>Z = np.dot(w.T,X) + b</h4><h4 id="A-sigmoid-Z"><a href="#A-sigmoid-Z" class="headerlink" title="A = sigmoid(Z)"></a>A = sigmoid(Z)</h4><h4 id="dZ-A-Y"><a href="#dZ-A-Y" class="headerlink" title="dZ = A-Y"></a>dZ = A-Y</h4><h4 id="dw-1-m-np-dot-X-dZ-T"><a href="#dw-1-m-np-dot-X-dZ-T" class="headerlink" title="dw = 1/m*np.dot(X,dZ.T)"></a>dw = 1/m*np.dot(X,dZ.T)</h4><h4 id="db-1-m-np-sum-dZ"><a href="#db-1-m-np-sum-dZ" class="headerlink" title="db = 1/m*np.sum(dZ)"></a>db = 1/m*np.sum(dZ)</h4><h4 id="w-w-alpha-dw"><a href="#w-w-alpha-dw" class="headerlink" title="w = w - alpha*dw"></a>w = w - alpha*dw</h4><h4 id="b-b-alpha-db"><a href="#b-b-alpha-db" class="headerlink" title="b = b - alpha*db"></a>b = b - alpha*db</h4><h2 id="8-python的notation"><a href="#8-python的notation" class="headerlink" title="8. python的notation"></a>8. python的notation</h2><h3 id="虽然在Python有广播的机制，但是在Python程序中，为了保证矩阵运算的正确性，可以使用reshape-函数来对矩阵设定所需要进行计算的维度，这是个好的习惯；"><a href="#虽然在Python有广播的机制，但是在Python程序中，为了保证矩阵运算的正确性，可以使用reshape-函数来对矩阵设定所需要进行计算的维度，这是个好的习惯；" class="headerlink" title="虽然在Python有广播的机制，但是在Python程序中，为了保证矩阵运算的正确性，可以使用reshape()函数来对矩阵设定所需要进行计算的维度，这是个好的习惯；"></a>虽然在Python有广播的机制，但是在Python程序中，为了保证矩阵运算的正确性，可以使用reshape()函数来对矩阵设定所需要进行计算的维度，这是个好的习惯；</h3><h3 id="如果用下列语句来定义一个向量，则这条语句生成的a的维度为（5，），既不是行向量也不是列向量，称为秩（rank）为1的array，如果对a进行转置，则会得到a本身，这在计算中会给我们带来一些问题。"><a href="#如果用下列语句来定义一个向量，则这条语句生成的a的维度为（5，），既不是行向量也不是列向量，称为秩（rank）为1的array，如果对a进行转置，则会得到a本身，这在计算中会给我们带来一些问题。" class="headerlink" title="如果用下列语句来定义一个向量，则这条语句生成的a的维度为（5，），既不是行向量也不是列向量，称为秩（rank）为1的array，如果对a进行转置，则会得到a本身，这在计算中会给我们带来一些问题。"></a>如果用下列语句来定义一个向量，则这条语句生成的a的维度为（5，），既不是行向量也不是列向量，称为秩（rank）为1的array，如果对a进行转置，则会得到a本身，这在计算中会给我们带来一些问题。</h3><pre><code class="python">a = np.random.randn(5)
</code></pre>
<h3 id="如果需要定义（5，1）或者（1，5）向量，要使用下面标准的语句："><a href="#如果需要定义（5，1）或者（1，5）向量，要使用下面标准的语句：" class="headerlink" title="如果需要定义（5，1）或者（1，5）向量，要使用下面标准的语句："></a>如果需要定义（5，1）或者（1，5）向量，要使用下面标准的语句：</h3><pre><code class="python">a = np.random.randn(5,1)
b = np.random.randn(1,5)
</code></pre>
<h3 id="可以使用assert语句对向量或数组的维度进行判断。assert会对内嵌语句进行判断，即判断a的维度是不是（5，1），如果不是，则程序在此处停止。使用assert语句也是一种很好的习惯，能够帮助我们及时检查、发现语句是否正确。"><a href="#可以使用assert语句对向量或数组的维度进行判断。assert会对内嵌语句进行判断，即判断a的维度是不是（5，1），如果不是，则程序在此处停止。使用assert语句也是一种很好的习惯，能够帮助我们及时检查、发现语句是否正确。" class="headerlink" title="可以使用assert语句对向量或数组的维度进行判断。assert会对内嵌语句进行判断，即判断a的维度是不是（5，1），如果不是，则程序在此处停止。使用assert语句也是一种很好的习惯，能够帮助我们及时检查、发现语句是否正确。"></a>可以使用assert语句对向量或数组的维度进行判断。assert会对内嵌语句进行判断，即判断a的维度是不是（5，1），如果不是，则程序在此处停止。使用assert语句也是一种很好的习惯，能够帮助我们及时检查、发现语句是否正确。</h3><pre><code class="python">assert(a.shape == (5,1))
</code></pre>
<h3 id="可以使用reshape函数对数组设定所需的维度"><a href="#可以使用reshape函数对数组设定所需的维度" class="headerlink" title="可以使用reshape函数对数组设定所需的维度"></a>可以使用reshape函数对数组设定所需的维度</h3><pre><code class="python">a.reshape((5,1))
</code></pre>

      
       
    </div>
</article>



<div class="article_copyright">
    <p><span>文章标题:</span>吴恩达深度学习笔记1-2--神经网络基础</p>
    <p><span>文章字数:</span><span class="post-count">1,699</span></p>
    <p><span>本文作者:</span><a href="javascript:void(0)" title="Wangjian">Wangjian</a></p>
    <p><span>发布时间:</span>2018-09-20, 22:27:05</p>
    <p><span>最后更新:</span>2018-09-20, 22:27:52</p>
    <span>原始链接:</span><a class="post-url" href="/2018/09/20/吴恩达Coursera深度学习课程笔记1-2--神经网络基础/" title="吴恩达深度学习笔记1-2--神经网络基础">http://yoursite.com/2018/09/20/吴恩达Coursera深度学习课程笔记1-2--神经网络基础/</a>
    <p>
        <span>版权声明:</span><i class="fa fa-creative-commons"></i> <a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/" title="CC BY-NC-SA 4.0 International" target = "_blank">"署名-非商用-相同方式共享 4.0"</a> 转载请保留原文链接及作者。
    </p>
</div>




    

    </div>
    <div class="copyright">
        <p class="footer-entry">©2017 Yelog</p>
<p class="footer-entry">Buit with <a href="https://hexo.io/" target="_blank">Hexo</a> and <a href="https://github.com/yelog/hexo-theme-3-hexo" target="_blank">3-hexo</a> theme</p>

    </div>
    <div class="full-toc">
        <button class="full"><span class="min "></span></button>
<button class="post-toc-menu"><span class="post-toc-menu-icons"></span></button>
<div class="post-toc"><span class="post-toc-title">目录</span>
    <div class="post-toc-content">

    </div>
</div>
<a class="" id="rocket" href="javascript:void(0)"></a>
    </div>
</div>
<div class="acParent"></div>

</body>
<script src="//cdn.bootcss.com/jquery.pjax/2.0.1/jquery.pjax.min.js"></script>

<script src="//cdn.bootcss.com/photoswipe/4.1.2/photoswipe.min.js"></script>
<script src="//cdn.bootcss.com/photoswipe/4.1.2/photoswipe-ui-default.min.js"></script>

<script src="/js/script.js"></script>
<script>
    var img_resize = 'photoSwipe';
    /*作者、标签的自动补全*/
    $(function () {
        $('.search').AutoComplete({
            'data': ['#hexo','#github','#小程序','#数据分析','#爬虫','#数据分析，深度学习',],
            'itemHeight': 20,
            'width': 418
        }).AutoComplete('show');
    })
    function initArticle() {
        /*渲染对应的表格样式*/
        
            $(".post .pjax table").addClass("green_title");
        

        /*渲染打赏样式*/
        

        /*高亮代码块行号*/
        

        /*访问数量*/
        
        $.getScript("//dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js");
        

        /*代码高亮，行号对齐*/
        $('.pre-numbering').css('line-height',$('.has-numbering').css('line-height'));

        

        // PhotoSwipe
        $('article').each(function(i){
            $(this).find('img').each(function(){
                if ($(this).closest('figure').hasClass('article-gallery-img')) {
                    return;
                }
                var alt = this.alt;
                $(this)
                    .wrap('<figure class="article-gallery-img" itemprop="associatedMedia" itemscope itemtype="http://schema.org/ImageObject"></figure>')
                    .wrap('<a href="' + this.src + '" title="' + alt + '"></a>');
                $(this).after('<div class="img_alt"><span>' + (alt || '') + '</span></div>');
            });
        });

        var pswpElement = document.querySelectorAll('.pswp')[0];
        if (pswpElement) {
            var gallerySelector = '.article-gallery, article';

            var initPhotoSwipeFromDOM = function(gallerySelector) {

                // parse slide data (url, title, size ...) from DOM elements
                // (children of gallerySelector)
                var parseThumbnailElements = function(el) {
                    var thumbElements = $(el).find('figure.article-gallery-img').toArray(),
                        numNodes = thumbElements.length,
                        items = [],
                        figureEl,
                        linkEl,
                        size,
                        imgEl,
                        item;

                    for (var i = 0; i < numNodes; i++) {

                        figureEl = thumbElements[i]; // <figure> element

                        // include only element nodes
                        if (figureEl.nodeType !== 1) {
                            continue;
                        }

                        linkEl = figureEl.children[0]; // <a> element
                        imgEl = linkEl.children[0]; // <img>

                        size = linkEl.getAttribute('data-size');
                        size = size && size.split('x');

                        // create slide object
                        item = {
                            src: linkEl.getAttribute('href'),
                            w: size && parseInt(size[0], 10) || imgEl.width,
                            h: size && parseInt(size[1], 10) || imgEl.height
                        };

                        if (figureEl.children.length > 1) {
                            // <figcaption> content
                            item.title = figureEl.children[1].innerHTML;
                        }

                        if (linkEl.children.length > 0) {
                            // <img> thumbnail element, retrieving thumbnail url
                            item.msrc = linkEl.children[0].getAttribute('src');
                        }

                        item.el = figureEl; // save link to element for getThumbBoundsFn
                        items.push(item);
                    }

                    return items;
                };

                // find nearest parent element
                var closest = function closest(el, fn) {
                    return el && (fn(el) ? el : closest(el.parentNode, fn));
                };

                // triggers when user clicks on thumbnail
                var onThumbnailsClick = function(e) {
                    e = e || window.event;

                    var eTarget = e.target || e.srcElement;

                    // find root element of slide
                    var clickedListItem = closest(eTarget, function(el) {
                        return (el.tagName && el.tagName.toUpperCase() === 'FIGURE');
                    });

                    if (!clickedListItem) {
                        return;
                    }

                    if (e.preventDefault) {
                        e.preventDefault();
                    } else {
                        e.returnValue = false;
                    }

                    // find index of clicked item by looping through all child nodes
                    // alternatively, you may define index via data- attribute
                    var clickedGallery = $(clickedListItem).closest(gallerySelector)[0],
                        childNodes = $(clickedGallery).find('figure.article-gallery-img').toArray(),
                        numChildNodes = childNodes.length,
                        nodeIndex = 0,
                        index;

                    for (var i = 0; i < numChildNodes; i++) {
                        if (childNodes[i].nodeType !== 1) {
                            continue;
                        }

                        if (childNodes[i] === clickedListItem) {
                            index = nodeIndex;
                            break;
                        }
                        nodeIndex++;
                    }



                    if (index >= 0) {
                        // open PhotoSwipe if valid index found
                        openPhotoSwipe(index, clickedGallery);
                    }
                    return false;
                };

                // parse picture index and gallery index from URL (#&pid=1&gid=2)
                var photoswipeParseHash = function() {
                    var hash = window.location.hash.substring(1),
                        params = {};

                    if (hash.length < 5) {
                        return params;
                    }

                    var vars = hash.split('&');
                    for (var i = 0; i < vars.length; i++) {
                        if (!vars[i]) {
                            continue;
                        }
                        var pair = vars[i].split('=');
                        if (pair.length < 2) {
                            continue;
                        }
                        params[pair[0]] = pair[1];
                    }

                    if (params.gid) {
                        params.gid = parseInt(params.gid, 10);
                    }

                    return params;
                };

                var openPhotoSwipe = function(index, galleryElement, disableAnimation, fromURL) {
                    var pswpElement = document.querySelectorAll('.pswp')[0],
                        gallery,
                        options,
                        items;

                    items = parseThumbnailElements(galleryElement);

                    // define options (if needed)
                    options = {

                        // define gallery index (for URL)
                        galleryUID: galleryElement.getAttribute('data-pswp-uid'),

                        getThumbBoundsFn: function(index) {
                            // See Options -> getThumbBoundsFn section of documentation for more info
                            var thumbnail = items[index].el.getElementsByTagName('img')[0], // find thumbnail
                                pageYScroll = window.pageYOffset || document.documentElement.scrollTop,
                                rect = thumbnail.getBoundingClientRect();

                            return {
                                x: rect.left,
                                y: rect.top + pageYScroll,
                                w: rect.width
                            };
                        }
                    };

                    // PhotoSwipe opened from URL
                    if (fromURL) {
                        if (options.galleryPIDs) {
                            // parse real index when custom PIDs are used
                            // http://photoswipe.com/documentation/faq.html#custom-pid-in-url
                            for (var j = 0; j < items.length; j++) {
                                if (items[j].pid == index) {
                                    options.index = j;
                                    break;
                                }
                            }
                        } else {
                            // in URL indexes start from 1
                            options.index = parseInt(index, 10) - 1;
                        }
                    } else {
                        options.index = parseInt(index, 10);
                    }

                    // exit if index not found
                    if (isNaN(options.index)) {
                        return;
                    }

                    if (disableAnimation) {
                        options.showAnimationDuration = 0;
                    }

                    // Pass data to PhotoSwipe and initialize it
                    gallery = new PhotoSwipe(pswpElement, PhotoSwipeUI_Default, items, options);

                    gallery.listen('imageLoadComplete', function(index, item) {
                        var linkEl = item.el.children[0];
                        var img = item.container.children[0];
                        if (!linkEl.getAttribute('data-size')) {
                            linkEl.setAttribute('data-size', img.naturalWidth + 'x' + img.naturalHeight);
                            item.w = img.naturalWidth;
                            item.h = img.naturalHeight;
                            gallery.invalidateCurrItems();
                            gallery.updateSize(true);
                        }
                    });

                    gallery.init();
                };

                // loop through all gallery elements and bind events
                var galleryElements = document.querySelectorAll(gallerySelector);

                for (var i = 0, l = galleryElements.length; i < l; i++) {
                    galleryElements[i].setAttribute('data-pswp-uid', i + 1);
                    galleryElements[i].onclick = onThumbnailsClick;
                }

                // Parse URL and open gallery if it contains #&pid=3&gid=1
                var hashData = photoswipeParseHash();
                if (hashData.pid && hashData.gid) {
                    openPhotoSwipe(hashData.pid, galleryElements[hashData.gid - 1], true, true);
                }
            };

            // execute above function
            initPhotoSwipeFromDOM(gallerySelector);
        }
        
    }

    /*打赏页面隐藏与展示*/
    

</script>

<!--加入行号的高亮代码块样式-->

<!--自定义样式设置-->
<style>
    
    .nav-right nav a.hover, #local-search-result a.hover{
        background-color: #e2e0e0;
    }
    
    

    /*列表样式*/
    
    .post .pjax article .article-entry>ol, .post .pjax article .article-entry>ul, .post .pjax article>ol, .post .pjax article>ul{
        border: #e2dede solid 2px;
        border-radius: 10px;
        padding: 10px 32px 10px 56px;
    }
    .post .pjax article .article-entry li>ol, .post .pjax article .article-entry li>ul,.post .pjax article li>ol, .post .pjax article li>ul{
        padding-top: 5px;
        padding-bottom: 5px;
    }
    .post .pjax article .article-entry>ol>li, .post .pjax article .article-entry>ul>li,.post .pjax article>ol>li, .post .pjax article>ul>li{
        margin-bottom: auto;
        margin-left: auto;
    }
    .post .pjax article .article-entry li>ol>li, .post .pjax article .article-entry li>ul>li,.post .pjax article li>ol>li, .post .pjax article li>ul>li{
        margin-bottom: auto;
        margin-left: auto;
    }
    

    /*引用块样式*/
    
    .post .pjax article blockquote {
        padding: 10px 20px;
        background-color: white;
        border: none;
        border-left: 4px solid #42b983;
        border-right: 4px solid #42b983;
        border-radius: 10px;
    }
    

    /*文章列表背景图*/
    
    .nav-right:before {
        content: ' ';
        display: block;
        position: absolute;
        left: 0;
        top: 0;
        width: 100%;
        height: 100%;
        opacity: 0.1;
        background: url("http://www.taopic.com/uploads/allimg/140504/235031-1405040UZ931.jpg");
        background-repeat: no-repeat;
        background-position: 50% 0;
        -ms-background-size: cover;
        -o-background-size: cover;
        -moz-background-size: cover;
        -webkit-background-size: cover;
        background-size: cover;
    }
    
</style>


<!-- Root element of PhotoSwipe. Must have class pswp. -->
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

    <!-- Background of PhotoSwipe.
         It's a separate element, as animating opacity is faster than rgba(). -->
    <div class="pswp__bg"></div>

    <!-- Slides wrapper with overflow:hidden. -->
    <div class="pswp__scroll-wrap">

        <!-- Container that holds slides. PhotoSwipe keeps only 3 slides in DOM to save memory. -->
        <!-- don't modify these 3 pswp__item elements, data is added later on. -->
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        <!-- Default (PhotoSwipeUI_Default) interface on top of sliding area. Can be changed. -->
        <div class="pswp__ui pswp__ui--hidden">

            <div class="pswp__top-bar">

                <!--  Controls are self-explanatory. Order can be changed. -->

                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>

                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>

                <!-- Preloader demo https://codepen.io/dimsemenov/pen/yyBWoR -->
                <!-- element will get class pswp__preloader--active when preloader is running -->
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                        <div class="pswp__preloader__cut">
                            <div class="pswp__preloader__donut"></div>
                        </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div>
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>

            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>

        </div>

    </div>

</div>





</html>
